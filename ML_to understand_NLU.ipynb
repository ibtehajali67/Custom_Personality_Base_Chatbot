{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to understand intent and extract entities\n",
    "\n",
    "import re\n",
    "\n",
    "keywords = {\n",
    " 'goodbye': ['bye', 'farewell'],\n",
    " 'greet': ['hello', 'hi', 'hey'],\n",
    " 'thankyou': ['thank', 'thx']\n",
    "}\n",
    "\n",
    "responses = {\n",
    " 'goodbye': ['bye', 'farewell'],\n",
    " 'greet': ['hello', 'hi', 'hey'],\n",
    " 'thankyou': ['thank', 'thx']\n",
    "}\n",
    "\n",
    "# Define a dictionary of patterns\n",
    "patterns = {}\n",
    "\n",
    "# Iterate over the keywords dictionary\n",
    "for intent, keys in keywords.items():\n",
    "    # Create regular expressions and compile them into pattern objects\n",
    "    patterns[intent] = re.compile('|'.join(keys))\n",
    "    \n",
    "# Print the patterns\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "bot_template = \"BOT : {0}\"\n",
    "user_template = \"USER : {0}\"\n",
    "\n",
    "# Define a function that sends a message to the bot: send_message\n",
    "def send_message(message):\n",
    "    # Print user_template including the user_message\n",
    "    print(user_template.format(message))\n",
    "    # Get the bot's response to the message\n",
    "    response = respond(message)\n",
    "    # Print the bot template including the bot's response.\n",
    "    print(bot_template.format(response))\n",
    "\n",
    "# Define a function to find the intent of a message\n",
    "def match_intent(message):\n",
    "    matched_intent = None\n",
    "    for intent, pattern in patterns.items():\n",
    "        # Check if the pattern occurs in the message \n",
    "        if pattern.search(message):\n",
    "            matched_intent = intent\n",
    "    return matched_intent\n",
    "\n",
    "# Define a respond function\n",
    "def respond(message):\n",
    "    # Call the match_intent function\n",
    "    intent = match_intent(message)\n",
    "    # Fall back to the default response\n",
    "    key = \"default\"\n",
    "    if intent in responses:\n",
    "        key = intent\n",
    "    return random.choice(responses[key])\n",
    "\n",
    "# Send messages\n",
    "send_message(\"hello!\")\n",
    "send_message(\"bye byeee\")\n",
    "send_message(\"thanks very much!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define find_name()\n",
    "def find_name(message):\n",
    "    name = None\n",
    "    # Create a pattern for checking if the keywords occur\n",
    "    name_keyword = re.compile(r\"(name|call)\")\n",
    "    # Create a pattern for finding capitalized words\n",
    "    name_pattern = re.compile(r\"(\\b[A-Z][a-z]*\\b)\")\n",
    "    if name_keyword.search(message):\n",
    "        # Get the matching words in the string\n",
    "        name_words = name_pattern.findall(message)\n",
    "        if len(name_words) > 0:\n",
    "            # Return the name if the keywords are present\n",
    "            name = ' '.join(name_words)\n",
    "    return name\n",
    "\n",
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Find the name\n",
    "    name = find_name(message)\n",
    "    if name is None:\n",
    "        return \"Hi there!\"\n",
    "    else:\n",
    "        return \"Hello, {0}!\".format(name)\n",
    "\n",
    "# Send messages\n",
    "send_message(\"my name is David Copperfield\")\n",
    "send_message(\"call me Ishmael\")\n",
    "send_message(\"People call me Cassandra\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('atis_intents.csv', 'r') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    labels = []\n",
    "    sentences = []\n",
    "    for row in readCSV:\n",
    "        label = row[0]\n",
    "        sentence = row[1]\n",
    "        labels.append(label)\n",
    "        sentences.append(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m spacy download en_vectors_web_lg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "# Load the spacy model: nlp\n",
    "nlp = spacy.load('en_vectors_web_lg')\n",
    "\n",
    "# Calculate the length of sentences\n",
    "n_sentences = len(sentences)\n",
    "\n",
    "print(n_sentences)\n",
    "\n",
    "# Calculate the dimensionality of nlp\n",
    "embedding_dim = nlp.vocab.vectors_length\n",
    "\n",
    "print(embedding_dim)\n",
    "\n",
    "# Initialize the array with zeros: X\n",
    "X = np.zeros((n_sentences, embedding_dim))\n",
    "\n",
    "# Iterate over the sentences\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    # Pass each each sentence to the nlp object to create a document\n",
    "    doc = nlp(sentence)\n",
    "    # Save the document's .vector attribute to the corresponding row in X\n",
    "    X[idx, :] = doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intent classification with sklearn\n",
    "\n",
    "# Import SVC\n",
    "from sklearn.svm import SVC\n",
    "# X_train and y_train was given.\n",
    "\n",
    "# Create a support vector classifier\n",
    "clf = SVC(C=1)\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Count the number of correct predictions\n",
    "n_correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        n_correct += 1\n",
    "\n",
    "print(\"Predicted {0} correctly out of {1} test examples\".format(n_correct, len(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define included entities\n",
    "include_entities = ['DATE', 'ORG', 'PERSON']\n",
    "\n",
    "# Define extract_entities()\n",
    "def extract_entities(message):\n",
    "    # Create a dict to hold the entities\n",
    "    ents = dict.fromkeys(include_entities)\n",
    "    # Create a spacy document\n",
    "    doc = nlp(message)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in include_entities:\n",
    "            # Save interesting entities\n",
    "            ents[ent.label_] = ent.text\n",
    "    return ents\n",
    "\n",
    "print(extract_entities('friends called Mary who have worked at Google since 2010'))\n",
    "print(extract_entities('people who graduated from MIT in 1999'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the document\n",
    "doc = nlp(\"let's see that jacket in red and some blue jeans\")\n",
    "\n",
    "# Iterate over parents in parse tree until an item entity is found\n",
    "def find_parent_item(word):\n",
    "    # Iterate over the word's ancestors\n",
    "    for parent in word.ancestors:\n",
    "        # Check for an \"item\" entity\n",
    "        if entity_type(parent) == \"item\":\n",
    "            return parent.text\n",
    "    return None\n",
    "\n",
    "# For all color entities, find their parent item\n",
    "def assign_colors(doc):\n",
    "    # Iterate over the document\n",
    "    for word in doc:\n",
    "        # Check for \"color\" entities\n",
    "        if entity_type(word) == \"color\":\n",
    "            # Find the parent\n",
    "            item = find_parent_item(word)\n",
    "            print(\"item: {0} has color : {1}\".format(item, word))\n",
    "\n",
    "# Assign the colors\n",
    "assign_colors(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "\n",
    "# Create args dictionary\n",
    "args = {\"pipeline\": \"spacy_sklearn\"}\n",
    "\n",
    "# Create a configuration and trainer\n",
    "config = RasaNLUModelConfig(args)\n",
    "print(config)\n",
    "trainer = Trainer(config)\n",
    "\n",
    "# Load the training data\n",
    "training_data = load_data(\"./sss.json\")\n",
    "\n",
    "# Create an interpreter by training the model\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# Try it out\n",
    "print(interpreter.parse(\"I'm looking for a Mexican restaurant in the North of town\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interpreter.parse(\"tell me your name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/training_data/training_data.py:184: UserWarning: Entity 'activities' has only 1 training examples! minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_ENTITY))\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/training_data/training_data.py:184: UserWarning: Entity 'birth' has only 1 training examples! minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_ENTITY))\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/training_data/training_data.py:184: UserWarning: Entity 'family_name' has only 1 training examples! minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_ENTITY))\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/training_data/training_data.py:184: UserWarning: Entity 'fav region' has only 1 training examples! minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_ENTITY))\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/training_data/training_data.py:184: UserWarning: Entity 'swimming' has only 1 training examples! minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_ENTITY))\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/extractors/entity_synonyms.py:105: UserWarning: Found conflicting synonym definitions for 'pla'. Overwriting target 'play' with 'plan'. Check your training data and remove conflicting synonym definitions to prevent this from happening.\n",
      "  repr(replacement)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:520: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:522: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:527: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:285: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:286: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:355: The name tf.losses.get_regularization_loss is deprecated. Please use tf.compat.v1.losses.get_regularization_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:537: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:540: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:411: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 1900/1900 [01:53<00:00, 16.73it/s, loss=0.165, acc=1.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:650: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:679: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/mitho/DemoChatBot2/DemoChatBot/project/default/test/component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Data-efficient entity recognition\n",
    "\n",
    "# Import necessary modules\n",
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "from rasa_nlu.model import Metadata, Interpreter\n",
    "# from tensorflow import set_random_seed\n",
    "# tf.set_random_seed(42) \n",
    "# sess = tf.Session()\n",
    "args = {\"pipeline\": \n",
    "    \"tensorflow_embedding\"}\n",
    "\n",
    "# Create a config that uses this pipeline \n",
    "config = RasaNLUModelConfig(args)\n",
    "# Create a trainer that uses this config\n",
    "trainer = Trainer(config)\n",
    "training_data = load_data(\"sss.json\")\n",
    "# Create an interpreter by training the model\n",
    "interpreter = trainer.train(training_data)\n",
    "model_dir=trainer.persist('project/',fixed_model_name = 'test')\n",
    "interpreter=interpreter.load(model_dir)\n",
    "\n",
    "# Parse some messages\n",
    "#print(interpreter.parse(\"show me Chinese food in the centre of town\"))\n",
    "#print(interpreter.parse(\"I want an Indian restaurant in the west\"))\n",
    "#print(interpreter.parse(\"are there any good pizza places in the center?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.model import Metadata, Interpreter\n",
    "interpreter = Interpreter.load('/home/mitho/DemoChatBot2/DemoChatBot/project/default/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"file3.csv\",encoding='mac_roman')\n",
    "df=df.set_index('Intents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intents</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ask_sup</th>\n",
       "      <td>Oh, Just the usual!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_health</th>\n",
       "      <td>Very well, thanks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ask_gender</th>\n",
       "      <td>Yes, I am a pretty girl.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ask_born_place</th>\n",
       "      <td>I was born in Japan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_religion</th>\n",
       "      <td>I am proud that I am an American citizen of Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_acne</th>\n",
       "      <td>Unfortunately Yes! whenever I used to eat exce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ask_arms</th>\n",
       "      <td>Yes, I have 2 forelimbs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ask_eyes</th>\n",
       "      <td>Yes, I have very beautiful greenish eyes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greet</th>\n",
       "      <td>Hey, Good Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_city</th>\n",
       "      <td>My favorite city is New York.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Answers\n",
       "Intents                                                          \n",
       "ask_sup                                       Oh, Just the usual!\n",
       "ask_health                                     Very well, thanks.\n",
       "Ask_gender                               Yes, I am a pretty girl.\n",
       "Ask_born_place                               I was born in Japan.\n",
       "ask_religion    I am proud that I am an American citizen of Ja...\n",
       "...                                                           ...\n",
       "ask_acne        Unfortunately Yes! whenever I used to eat exce...\n",
       "Ask_arms                                 Yes, I have 2 forelimbs.\n",
       "Ask_eyes               Yes, I have very beautiful greenish eyes. \n",
       "greet                                           Hey, Good Evening\n",
       "ask_city                            My favorite city is New York.\n",
       "\n",
       "[77 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter username:favorite book\n",
      "{'intent': {'name': 'ask_book', 'confidence': 0.9284505248069763}, 'entities': [], 'intent_ranking': [{'name': 'ask_book', 'confidence': 0.9284505248069763}, {'name': 'ask_yawn', 'confidence': 0.3006148338317871}, {'name': 'ask_eyes', 'confidence': 0.2680564522743225}, {'name': 'ask_lead', 'confidence': 0.2469063401222229}, {'name': 'ask_tired', 'confidence': 0.2287183403968811}, {'name': 'ask_date_birth', 'confidence': 0.21841317415237427}, {'name': 'ask_health', 'confidence': 0.21036700904369354}, {'name': 'ask_country', 'confidence': 0.20145606994628906}, {'name': 'ask_life_stage', 'confidence': 0.19621795415878296}, {'name': 'ask_glasses', 'confidence': 0.19499269127845764}], 'text': 'favorite book'}\n",
      "[]\n",
      "0.9284505248069763\n",
      "ask_book\n",
      "The Millionaire Next Door is my favorite book\n"
     ]
    }
   ],
   "source": [
    "username = input(\"Enter username:\")\n",
    "a=interpreter.parse(username)\n",
    "print(a)\n",
    "b=a['intent']['name']\n",
    "c = a['intent']['confidence']\n",
    "t=a['entities']\n",
    "print(t)\n",
    "print(c)\n",
    "print(b)\n",
    "if c>=0.80:\n",
    "    print(df.loc[b].values[0])\n",
    "else:\n",
    "    print(\"doesn't get your point can you ask\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
