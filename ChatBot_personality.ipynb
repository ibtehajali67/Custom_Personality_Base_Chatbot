{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:678: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-01-28 17:14:10.170398: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-01-28 17:14:10.189196: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\n",
      "2021-01-28 17:14:10.189439: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x8196280 executing computations on platform Host. Devices:\n",
      "2021-01-28 17:14:10.189452: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:679: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2021-01-28 17:14:10.288596: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "WARNING:tensorflow:From /home/mitho/DemoChatBot2/DemoChatBot/env/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:683: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "17:14:10 | \u001b[33mOverriding opt[\"model_file\"] to /home/mitho/DemoChatBot2/DemoChatBot/data/models/tutorial_transformer_generator/model (previously: /checkpoint/roller/20190909/cleanreddit/585/model)\u001b[0m\n",
      "17:14:10 | \u001b[33mLoading model with `--beam-block-full-context false`\u001b[0m\n",
      "17:14:10 | Using CUDA\n",
      "17:14:10 | \u001b[31mYou set --fp16 true with --fp16-impl apex, but fp16 with apex is unavailable. To use apex fp16, please install APEX from https://github.com/NVIDIA/apex.\u001b[0m\n",
      "17:14:10 | loading dictionary from /home/mitho/DemoChatBot2/DemoChatBot/data/models/tutorial_transformer_generator/model.dict\n",
      "17:14:10 | num words = 54944\n",
      "17:14:10 | TransformerGenerator: full interactive mode on.\n",
      "17:14:11 | \u001b[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001b[0m\n",
      "17:14:13 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
      "17:14:13 | Loading existing model params from /home/mitho/DemoChatBot2/DemoChatBot/data/models/tutorial_transformer_generator/model\n",
      "17:14:13 | Opt:\n",
      "17:14:13 |     activation: gelu\n",
      "17:14:13 |     adafactor_eps: '(1e-30, 0.001)'\n",
      "17:14:13 |     adam_eps: 1e-06\n",
      "17:14:13 |     add_p1_after_newln: False\n",
      "17:14:13 |     aggregate_micro: False\n",
      "17:14:13 |     allow_missing_init_opts: False\n",
      "17:14:13 |     attention_dropout: 0.0\n",
      "17:14:13 |     batch_length_range: 5\n",
      "17:14:13 |     batch_sort_cache_type: pop\n",
      "17:14:13 |     batch_sort_field: text\n",
      "17:14:13 |     batchsize: 48\n",
      "17:14:13 |     beam_block_full_context: False\n",
      "17:14:13 |     beam_block_list_filename: None\n",
      "17:14:13 |     beam_block_ngram: 3\n",
      "17:14:13 |     beam_context_block_ngram: 3\n",
      "17:14:13 |     beam_delay: 30\n",
      "17:14:13 |     beam_length_penalty: 0.65\n",
      "17:14:13 |     beam_min_length: 10\n",
      "17:14:13 |     beam_min_n_best: 3\n",
      "17:14:13 |     beam_size: 8\n",
      "17:14:13 |     betas: '[0.9, 0.98]'\n",
      "17:14:13 |     bpe_add_prefix_space: None\n",
      "17:14:13 |     bpe_debug: False\n",
      "17:14:13 |     bpe_merge: None\n",
      "17:14:13 |     bpe_vocab: None\n",
      "17:14:13 |     compute_tokenized_bleu: False\n",
      "17:14:13 |     datapath: /home/mitho/DemoChatBot2/DemoChatBot/data\n",
      "17:14:13 |     datatype: train:stream\n",
      "17:14:13 |     delimiter: '\\n'\n",
      "17:14:13 |     dict_build_first: True\n",
      "17:14:13 |     dict_class: parlai.core.dict:DictionaryAgent\n",
      "17:14:13 |     dict_endtoken: __end__\n",
      "17:14:13 |     dict_file: /home/mitho/DemoChatBot2/DemoChatBot/data/models/tutorial_transformer_generator/model.dict\n",
      "17:14:13 |     dict_include_test: False\n",
      "17:14:13 |     dict_include_valid: False\n",
      "17:14:13 |     dict_initpath: None\n",
      "17:14:13 |     dict_language: english\n",
      "17:14:13 |     dict_loaded: True\n",
      "17:14:13 |     dict_lower: True\n",
      "17:14:13 |     dict_max_ngram_size: -1\n",
      "17:14:13 |     dict_maxexs: -1\n",
      "17:14:13 |     dict_maxtokens: -1\n",
      "17:14:13 |     dict_minfreq: 0\n",
      "17:14:13 |     dict_nulltoken: __null__\n",
      "17:14:13 |     dict_starttoken: __start__\n",
      "17:14:13 |     dict_textfields: text,labels\n",
      "17:14:13 |     dict_tokenizer: bpe\n",
      "17:14:13 |     dict_unktoken: __unk__\n",
      "17:14:13 |     display_examples: False\n",
      "17:14:13 |     display_ignore_fields: label_candidates,text_candidates\n",
      "17:14:13 |     display_prettify: False\n",
      "17:14:13 |     distributed_world_size: 64\n",
      "17:14:13 |     download_path: None\n",
      "17:14:13 |     dropout: 0.1\n",
      "17:14:13 |     dynamic_batching: None\n",
      "17:14:13 |     embedding_projection: random\n",
      "17:14:13 |     embedding_size: 512\n",
      "17:14:13 |     embedding_type: random\n",
      "17:14:13 |     embeddings_scale: True\n",
      "17:14:13 |     eval_batchsize: None\n",
      "17:14:13 |     evaltask: None\n",
      "17:14:13 |     ffn_size: 2048\n",
      "17:14:13 |     force_fp16_tokens: True\n",
      "17:14:13 |     fp16: True\n",
      "17:14:13 |     fp16_impl: apex\n",
      "17:14:13 |     gpu: 0\n",
      "17:14:13 |     gradient_clip: 10.0\n",
      "17:14:13 |     hf_skip_special_tokens: True\n",
      "17:14:13 |     hide_labels: False\n",
      "17:14:13 |     history_add_global_end_token: None\n",
      "17:14:13 |     history_reversed: False\n",
      "17:14:13 |     history_size: -1\n",
      "17:14:13 |     host: localhost\n",
      "17:14:13 |     image_cropsize: 224\n",
      "17:14:13 |     image_mode: raw\n",
      "17:14:13 |     image_size: 256\n",
      "17:14:13 |     inference: beam\n",
      "17:14:13 |     init_model: None\n",
      "17:14:13 |     init_opt: None\n",
      "17:14:13 |     interactive_mode: True\n",
      "17:14:13 |     interactive_task: True\n",
      "17:14:13 |     invsqrt_lr_decay_gamma: -1\n",
      "17:14:13 |     label_truncate: 128\n",
      "17:14:13 |     learn_positional_embeddings: True\n",
      "17:14:13 |     learningrate: 0.0005\n",
      "17:14:13 |     load_from_checkpoint: True\n",
      "17:14:13 |     local_human_candidates_file: None\n",
      "17:14:13 |     log_every_n_secs: 30.0\n",
      "17:14:13 |     log_keep_fields: all\n",
      "17:14:13 |     loglevel: info\n",
      "17:14:13 |     lr_scheduler: invsqrt\n",
      "17:14:13 |     lr_scheduler_decay: 0.5\n",
      "17:14:13 |     lr_scheduler_patience: 3\n",
      "17:14:13 |     max_lr_steps: -1\n",
      "17:14:13 |     max_train_time: -1\n",
      "17:14:13 |     metrics: default\n",
      "17:14:13 |     model: transformer/generator\n",
      "17:14:13 |     model_file: /home/mitho/DemoChatBot2/DemoChatBot/data/models/tutorial_transformer_generator/model\n",
      "17:14:13 |     model_parallel: False\n",
      "17:14:13 |     momentum: 0\n",
      "17:14:13 |     multitask_weights: [1]\n",
      "17:14:13 |     n_decoder_layers: -1\n",
      "17:14:13 |     n_encoder_layers: -1\n",
      "17:14:13 |     n_heads: 16\n",
      "17:14:13 |     n_layers: 8\n",
      "17:14:13 |     n_positions: 512\n",
      "17:14:13 |     n_segments: 0\n",
      "17:14:13 |     nesterov: True\n",
      "17:14:13 |     no_cuda: False\n",
      "17:14:13 |     num_epochs: 5.0\n",
      "17:14:13 |     numthreads: 1\n",
      "17:14:13 |     numworkers: 4\n",
      "17:14:13 |     nus: [0.7]\n",
      "17:14:13 |     optimizer: fused_adam\n",
      "17:14:13 |     outfile: \n",
      "17:14:13 |     output_scaling: 1.0\n",
      "17:14:13 |     override: \"{'model_file': '/home/mitho/DemoChatBot2/DemoChatBot/data/models/tutorial_transformer_generator/model'}\"\n",
      "17:14:13 |     parlai_home: /home/mitho/DemoChatBot2/DemoChatBot\n",
      "17:14:13 |     person_tokens: False\n",
      "17:14:13 |     port: 61337\n",
      "17:14:13 |     pytorch_context_length: -1\n",
      "17:14:13 |     pytorch_datapath: None\n",
      "17:14:13 |     pytorch_include_labels: True\n",
      "17:14:13 |     pytorch_preprocess: False\n",
      "17:14:13 |     pytorch_teacher_batch_sort: False\n",
      "17:14:13 |     pytorch_teacher_dataset: None\n",
      "17:14:13 |     pytorch_teacher_task: None\n",
      "17:14:13 |     rank_candidates: False\n",
      "17:14:13 |     relu_dropout: 0.0\n",
      "17:14:13 |     save_after_valid: True\n",
      "17:14:13 |     save_every_n_secs: -1\n",
      "17:14:13 |     save_format: conversations\n",
      "17:14:13 |     share_word_embeddings: True\n",
      "17:14:13 |     short_final_eval: True\n",
      "17:14:13 |     show_advanced_args: False\n",
      "17:14:13 |     shuffle: False\n",
      "17:14:13 |     single_turn: False\n",
      "17:14:13 |     skip_generation: False\n",
      "17:14:13 |     special_tok_lst: None\n",
      "17:14:13 |     split_lines: False\n",
      "17:14:13 |     starttime: Jan28_17-14\n",
      "17:14:13 |     task: internal:new_reddit:presorted\n",
      "17:14:13 |     temperature: 1.0\n",
      "17:14:13 |     tensorboard_log: False\n",
      "17:14:13 |     text_truncate: 512\n",
      "17:14:13 |     topk: 10\n",
      "17:14:13 |     topp: 0.9\n",
      "17:14:13 |     truncate: -1\n",
      "17:14:13 |     update_freq: 1\n",
      "17:14:13 |     use_reply: label\n",
      "17:14:13 |     validation_cutoff: 1.0\n",
      "17:14:13 |     validation_every_n_epochs: -1\n",
      "17:14:13 |     validation_every_n_secs: 1800.0\n",
      "17:14:13 |     validation_max_exs: 9920\n",
      "17:14:13 |     validation_metric: ppl\n",
      "17:14:13 |     validation_metric_mode: min\n",
      "17:14:13 |     validation_patience: 0\n",
      "17:14:13 |     validation_share_agent: False\n",
      "17:14:13 |     variant: xlm\n",
      "17:14:13 |     verbose: False\n",
      "17:14:13 |     warmup_rate: 0.0001\n",
      "17:14:13 |     warmup_updates: 20000\n",
      "17:14:13 |     weight_decay: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:14:13 | Current ParlAI commit: 952f515d6eb4a073df977a58cd55bc3d341a0910\n",
      "17:14:13 | creating task(s): internal:new_reddit:presorted\n",
      "17:14:13 | http://localhost:5006/\n",
      "127.0.0.1 - - [28/Jan/2021 17:14:19] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jan/2021 17:14:19] \"GET /favicon.ico HTTP/1.1\" 202 -\n",
      "127.0.0.1 - - [28/Jan/2021 17:14:22] \"POST /interact HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jan/2021 17:14:26] \"POST /interact HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jan/2021 17:14:30] \"POST /interact HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jan/2021 17:14:40] \"POST /interact HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jan/2021 17:14:50] \"POST /interact HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jan/2021 17:14:57] \"POST /interact HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jan/2021 17:15:03] \"POST /interact HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "!python \"abc.py\" -mf \"zoo:tutorial_transformer_generator/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
